{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from IPython import get_ipython\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "from dynamic_env import TaskEnv_drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),  # 输入维度是 state_dim\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_dim),  # 输出维度是 action_dim\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.fc(state)\n",
    "\n",
    "# 定义 MAML 算法\n",
    "class MAML:\n",
    "    def __init__(self, state_dim, action_dim, lr_inner=0.01, lr_outer=0.001):\n",
    "        self.policy = PolicyNetwork(state_dim, action_dim)\n",
    "        self.lr_inner = lr_inner  # 内循环学习率\n",
    "        self.lr_outer = lr_outer  # 外循环学习率\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr_outer)\n",
    "\n",
    "    def adapt(self, task, num_steps=1):\n",
    "        \"\"\"\n",
    "        内循环：在单个任务上快速适应\n",
    "        \"\"\"\n",
    "        fast_weights = list(self.policy.parameters())  # 获取所有参数的副本\n",
    "        for step in range(num_steps):\n",
    "            states, actions, rewards = self.sample_trajectory(task)\n",
    "            loss = self.compute_loss(states, actions, rewards)\n",
    "            grads = torch.autograd.grad(loss, fast_weights, create_graph=True)\n",
    "            fast_weights = [w - self.lr_inner * g for w, g in zip(fast_weights, grads)]\n",
    "        return fast_weights\n",
    "\n",
    "    def meta_train(self, tasks: list[TaskEnv_drift], num_iterations=20):\n",
    "        \"\"\"\n",
    "        外循环：在多个任务上优化初始参数\n",
    "        \"\"\"\n",
    "        for iteration in range(num_iterations):\n",
    "            self.optimizer.zero_grad()\n",
    "            meta_loss = 0\n",
    "            for task in tasks:\n",
    "                fast_weights = self.adapt(task)\n",
    "                states, actions, rewards = self.sample_trajectory(task, fast_weights)\n",
    "                loss = self.compute_loss(states, actions, rewards, fast_weights)\n",
    "                meta_loss += loss\n",
    "            meta_loss /= len(tasks)\n",
    "            meta_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            print(f\"Iteration {iteration}, Meta Loss: {meta_loss.item()}\")\n",
    "\n",
    "    def compute_loss(self, states, actions, rewards, params=None):\n",
    "        \"\"\"\n",
    "        计算策略梯度损失\n",
    "        \"\"\"\n",
    "        if params is None:\n",
    "            probs = self.policy(states)\n",
    "        else:\n",
    "            probs = self.forward_with_params(states, params)\n",
    "        log_probs = torch.log(probs.gather(1, actions.unsqueeze(1)))\n",
    "        loss = -(log_probs * rewards).mean()\n",
    "        return loss\n",
    "\n",
    "    def forward_with_params(self, states, params):\n",
    "        x = states\n",
    "        param_iter = iter(params)  # 创建一个参数迭代器\n",
    "        for layer in self.policy.fc:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                weight = next(param_iter)  # 获取权重\n",
    "                bias = next(param_iter)    # 获取偏置\n",
    "                x = torch.nn.functional.linear(x, weight, bias)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def sample_trajectory(self, task: TaskEnv_drift, params=None):\n",
    "        \"\"\"\n",
    "        在任务中采样一条轨迹\n",
    "        \"\"\"\n",
    "        states, actions, rewards = [], [], []\n",
    "        state = task.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # 将状态转换为 one-hot 编码\n",
    "            state_idx = task.states.index(state)  # 获取状态的索引\n",
    "            state_onehot = np.zeros(len(task.states))  # 创建 one-hot 向量\n",
    "            state_onehot[state_idx] = 1\n",
    "            state_tensor = torch.FloatTensor(state_onehot)  # 转换为 PyTorch 张量\n",
    "\n",
    "            # 选择动作\n",
    "            if params is None:\n",
    "                action_probs = self.policy(state_tensor)\n",
    "            else:\n",
    "                action_probs = self.forward_with_params(state_tensor, params)\n",
    "            action = torch.multinomial(action_probs, 1).item()\n",
    "\n",
    "            # 执行动作\n",
    "            next_state, reward, done, _ = task.step(action)\n",
    "\n",
    "            # 存储轨迹数据\n",
    "            states.append(state_tensor)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            state = next_state\n",
    "\n",
    "        # 将轨迹数据转换为 PyTorch 张量\n",
    "        states = torch.stack(states)\n",
    "        actions = torch.LongTensor(actions)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        return states, actions, rewards\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift happen\n",
      "drift happen\n",
      "drift happen\n",
      "drift happen\n",
      "<TaskEnv_drift instance>\n",
      "5 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/veetin/Desktop/drifttest_pa/main/dynamic_env.py:47: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frequencies[label][action] = ast.literal_eval(frequencies[label][action]) #判断需要计算的内容是不是合法的Python类型，如果是则执行，否则就报错\n",
      "/Users/veetin/Desktop/drifttest_pa/main/dynamic_env.py:47: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frequencies[label][action] = ast.literal_eval(frequencies[label][action]) #判断需要计算的内容是不是合法的Python类型，如果是则执行，否则就报错\n",
      "/Users/veetin/Desktop/drifttest_pa/main/dynamic_env.py:47: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frequencies[label][action] = ast.literal_eval(frequencies[label][action]) #判断需要计算的内容是不是合法的Python类型，如果是则执行，否则就报错\n",
      "/Users/veetin/Desktop/drifttest_pa/main/dynamic_env.py:47: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frequencies[label][action] = ast.literal_eval(frequencies[label][action]) #判断需要计算的内容是不是合法的Python类型，如果是则执行，否则就报错\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义任务\n",
    "    tasks = []\n",
    "    for _ in range(4):\n",
    "        task = TaskEnv_drift()\n",
    "        if np.random.rand() < 0.5:  # 50% 的概率添加 drift\n",
    "            task.set_flag()\n",
    "            task.drift(add_actions=0, add_states=0)  # 只有transition metrix变化\n",
    "        tasks.append(task)\n",
    "\n",
    "    print(tasks[0])\n",
    "\n",
    "    # 初始化 MAML\n",
    "    state_dim = len(tasks[0].states)  # 状态空间大小\n",
    "    action_dim = len(tasks[0].motions)  # 动作空间大小\n",
    "    print(state_dim,action_dim)\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Meta Loss: -4.0154032707214355\n",
      "Iteration 1, Meta Loss: -3.3095688819885254\n",
      "Iteration 2, Meta Loss: 0.49231788516044617\n",
      "Iteration 3, Meta Loss: -2.5166015625\n",
      "Iteration 4, Meta Loss: -3.198366641998291\n",
      "Iteration 5, Meta Loss: -6.794022560119629\n",
      "Iteration 6, Meta Loss: -2.3016016483306885\n",
      "Iteration 7, Meta Loss: -2.749467372894287\n",
      "Iteration 8, Meta Loss: -1.114458441734314\n",
      "Iteration 9, Meta Loss: -3.8135173320770264\n"
     ]
    }
   ],
   "source": [
    "    maml = MAML(state_dim, action_dim)\n",
    "    # 元训练\n",
    "    maml.meta_train(tasks, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift happen\n",
      "Test Loss: 1.8209065198898315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/veetin/Desktop/drifttest_pa/main/dynamic_env.py:47: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frequencies[label][action] = ast.literal_eval(frequencies[label][action]) #判断需要计算的内容是不是合法的Python类型，如果是则执行，否则就报错\n"
     ]
    }
   ],
   "source": [
    "test_task = TaskEnv_drift()\n",
    "test_task.set_flag()\n",
    "test_task.drift(add_actions=0, add_states=0)  # 添加 2 个新动作和 2 个新状态\n",
    "fast_weights = maml.adapt(test_task)\n",
    "states, actions, rewards = maml.sample_trajectory(test_task, fast_weights)\n",
    "test_loss = maml.compute_loss(states, actions, rewards, fast_weights)\n",
    "print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
